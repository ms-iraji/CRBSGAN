{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCQefrrouvRI"
      },
      "outputs": [],
      "source": [
        "#load train data\n",
        "from __future__ import print_function\n",
        "\n",
        "import sys\n",
        "import os, sys, tarfile, errno\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "if sys.version_info >= (3, 0, 0):\n",
        "    import urllib.request as urllib # ugly but works\n",
        "else:\n",
        "    import urllib\n",
        "\n",
        "try:\n",
        "    from imageio import imsave\n",
        "except:\n",
        "    from scipy.misc import imsave\n",
        "\n",
        "print(sys.version_info)\n",
        "\n",
        "# image shape\n",
        "HEIGHT = 96\n",
        "WIDTH = 96\n",
        "DEPTH = 3\n",
        "\n",
        "# size of a single image in bytes\n",
        "SIZE = HEIGHT * WIDTH * DEPTH\n",
        "\n",
        "# path to the directory with the data\n",
        "DATA_DIR = './data'\n",
        "\n",
        "# url of the binary data\n",
        "DATA_URL = 'http://ai.stanford.edu/~acoates/stl10/stl10_binary.tar.gz'\n",
        "\n",
        "# path to the binary train file with image data\n",
        "DATA_PATH = './data/stl10_binary/train_X.bin'\n",
        "\n",
        "# path to the binary train file with labels\n",
        "LABEL_PATH = './data/stl10_binary/train_y.bin'\n",
        "\n",
        "def read_labels(path_to_labels):\n",
        "    \"\"\"\n",
        "    :param path_to_labels: path to the binary file containing labels from the STL-10 dataset\n",
        "    :return: an array containing the labels\n",
        "    \"\"\"\n",
        "    with open(path_to_labels, 'rb') as f:\n",
        "        labels = np.fromfile(f, dtype=np.uint8)\n",
        "        return labels\n",
        "\n",
        "\n",
        "def read_all_images(path_to_data):\n",
        "    \"\"\"\n",
        "    :param path_to_data: the file containing the binary images from the STL-10 dataset\n",
        "    :return: an array containing all the images\n",
        "    \"\"\"\n",
        "\n",
        "    with open(path_to_data, 'rb') as f:\n",
        "        # read whole file in uint8 chunks\n",
        "        everything = np.fromfile(f, dtype=np.uint8)\n",
        "\n",
        "        # We force the data into 3x96x96 chunks, since the\n",
        "        # images are stored in \"column-major order\", meaning\n",
        "        # that \"the first 96*96 values are the red channel,\n",
        "        # the next 96*96 are green, and the last are blue.\"\n",
        "        # The -1 is since the size of the pictures depends\n",
        "        # on the input file, and this way numpy determines\n",
        "        # the size on its own.\n",
        "\n",
        "        images = np.reshape(everything, (-1, 3, 96, 96))\n",
        "\n",
        "        # Now transpose the images into a standard image format\n",
        "        # readable by, for example, matplotlib.imshow\n",
        "        # You might want to comment this line or reverse the shuffle\n",
        "        # if you will use a learning algorithm like CNN, since they like\n",
        "        # their channels separated.\n",
        "        images = np.transpose(images, (0, 3, 2, 1))\n",
        "        return images\n",
        "\n",
        "\n",
        "def read_single_image(image_file):\n",
        "    \"\"\"\n",
        "    CAREFUL! - this method uses a file as input instead of the path - so the\n",
        "    position of the reader will be remembered outside of context of this method.\n",
        "    :param image_file: the open file containing the images\n",
        "    :return: a single image\n",
        "    \"\"\"\n",
        "    # read a single image, count determines the number of uint8's to read\n",
        "    image = np.fromfile(image_file, dtype=np.uint8, count=SIZE)\n",
        "    # force into image matrix\n",
        "    image = np.reshape(image, (3, 96, 96))\n",
        "    # transpose to standard format\n",
        "    # You might want to comment this line or reverse the shuffle\n",
        "    # if you will use a learning algorithm like CNN, since they like\n",
        "    # their channels separated.\n",
        "    image = np.transpose(image, (2, 1, 0))\n",
        "    return image\n",
        "\n",
        "\n",
        "def plot_image(image):\n",
        "    \"\"\"\n",
        "    :param image: the image to be plotted in a 3-D matrix format\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "    plt.imshow(image)\n",
        "    plt.show()\n",
        "\n",
        "def save_image(image, name):\n",
        "    imsave(\"%s.png\" % name, image, format=\"png\")\n",
        "\n",
        "def download_and_extract():\n",
        "    \"\"\"\n",
        "    Download and extract the STL-10 dataset\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "    dest_directory = DATA_DIR\n",
        "    if not os.path.exists(dest_directory):\n",
        "        os.makedirs(dest_directory)\n",
        "    filename = DATA_URL.split('/')[-1]\n",
        "    filepath = os.path.join(dest_directory, filename)\n",
        "    if not os.path.exists(filepath):\n",
        "        def _progress(count, block_size, total_size):\n",
        "            sys.stdout.write('\\rDownloading %s %.2f%%' % (filename,\n",
        "                float(count * block_size) / float(total_size) * 100.0))\n",
        "            sys.stdout.flush()\n",
        "        filepath, _ = urllib.urlretrieve(DATA_URL, filepath, reporthook=_progress)\n",
        "        print('Downloaded', filename)\n",
        "        tarfile.open(filepath, 'r:gz').extractall(dest_directory)\n",
        "\n",
        "def save_images(images, labels):\n",
        "    print(\"Saving images to disk\")\n",
        "    i = 0\n",
        "    for image in images:\n",
        "        label = labels[i]\n",
        "        directory = './img/' + str(label) + '/'\n",
        "        try:\n",
        "            os.makedirs(directory, exist_ok=True)\n",
        "        except OSError as exc:\n",
        "            if exc.errno == errno.EEXIST:\n",
        "                pass\n",
        "        filename = directory + str(i)\n",
        "        print(filename)\n",
        "        save_image(image, filename)\n",
        "        i = i+1\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # download data if needed\n",
        "    download_and_extract()\n",
        "\n",
        "    # test to check if the image is read correctly\n",
        "    with open(DATA_PATH) as f:\n",
        "        image = read_single_image(f)\n",
        "        plot_image(image)\n",
        "\n",
        "    # test to check if the whole dataset is read correctly\n",
        "    images = read_all_images(DATA_PATH)\n",
        "    print(images.shape)\n",
        "\n",
        "    labels = read_labels(LABEL_PATH)\n",
        "    print(labels.shape)\n",
        "\n",
        "    # save images to disk\n",
        "    save_images(images, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsigA5Q8BgKL"
      },
      "outputs": [],
      "source": [
        "#load test data\n",
        "from __future__ import print_function\n",
        "\n",
        "import sys\n",
        "import os, sys, tarfile, errno\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "if sys.version_info >= (3, 0, 0):\n",
        "    import urllib.request as urllib # ugly but works\n",
        "else:\n",
        "    import urllib\n",
        "\n",
        "try:\n",
        "    from imageio import imsave\n",
        "except:\n",
        "    from scipy.misc import imsave\n",
        "\n",
        "print(sys.version_info)\n",
        "\n",
        "# image shape\n",
        "HEIGHT = 96\n",
        "WIDTH = 96\n",
        "DEPTH = 3\n",
        "\n",
        "# size of a single image in bytes\n",
        "SIZE = HEIGHT * WIDTH * DEPTH\n",
        "\n",
        "# path to the directory with the data\n",
        "DATA_DIR = './data'\n",
        "\n",
        "# url of the binary data\n",
        "DATA_URL = 'http://ai.stanford.edu/~acoates/stl10/stl10_binary.tar.gz'\n",
        "\n",
        "# path to the binary train file with image data\n",
        "DATA_PATH = './data/stl10_binary/test_X.bin'\n",
        "\n",
        "# path to the binary train file with labels\n",
        "LABEL_PATH = './data/stl10_binary/test_y.bin'\n",
        "\n",
        "def read_labels(path_to_labels):\n",
        "    \"\"\"\n",
        "    :param path_to_labels: path to the binary file containing labels from the STL-10 dataset\n",
        "    :return: an array containing the labels\n",
        "    \"\"\"\n",
        "    with open(path_to_labels, 'rb') as f:\n",
        "        labels = np.fromfile(f, dtype=np.uint8)\n",
        "        return labels\n",
        "\n",
        "\n",
        "def read_all_images(path_to_data):\n",
        "    \"\"\"\n",
        "    :param path_to_data: the file containing the binary images from the STL-10 dataset\n",
        "    :return: an array containing all the images\n",
        "    \"\"\"\n",
        "\n",
        "    with open(path_to_data, 'rb') as f:\n",
        "        # read whole file in uint8 chunks\n",
        "        everything = np.fromfile(f, dtype=np.uint8)\n",
        "\n",
        "        # We force the data into 3x96x96 chunks, since the\n",
        "        # images are stored in \"column-major order\", meaning\n",
        "        # that \"the first 96*96 values are the red channel,\n",
        "        # the next 96*96 are green, and the last are blue.\"\n",
        "        # The -1 is since the size of the pictures depends\n",
        "        # on the input file, and this way numpy determines\n",
        "        # the size on its own.\n",
        "\n",
        "        images = np.reshape(everything, (-1, 3, 96, 96))\n",
        "\n",
        "        # Now transpose the images into a standard image format\n",
        "        # readable by, for example, matplotlib.imshow\n",
        "        # You might want to comment this line or reverse the shuffle\n",
        "        # if you will use a learning algorithm like CNN, since they like\n",
        "        # their channels separated.\n",
        "        images = np.transpose(images, (0, 3, 2, 1))\n",
        "        return images\n",
        "\n",
        "\n",
        "def read_single_image(image_file):\n",
        "    \"\"\"\n",
        "    CAREFUL! - this method uses a file as input instead of the path - so the\n",
        "    position of the reader will be remembered outside of context of this method.\n",
        "    :param image_file: the open file containing the images\n",
        "    :return: a single image\n",
        "    \"\"\"\n",
        "    # read a single image, count determines the number of uint8's to read\n",
        "    image = np.fromfile(image_file, dtype=np.uint8, count=SIZE)\n",
        "    # force into image matrix\n",
        "    image = np.reshape(image, (3, 96, 96))\n",
        "    # transpose to standard format\n",
        "    # You might want to comment this line or reverse the shuffle\n",
        "    # if you will use a learning algorithm like CNN, since they like\n",
        "    # their channels separated.\n",
        "    image = np.transpose(image, (2, 1, 0))\n",
        "    return image\n",
        "\n",
        "\n",
        "def plot_image(image):\n",
        "    \"\"\"\n",
        "    :param image: the image to be plotted in a 3-D matrix format\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "    plt.imshow(image)\n",
        "    plt.show()\n",
        "\n",
        "def save_image(image, name):\n",
        "    imsave(\"%s.png\" % name, image, format=\"png\")\n",
        "\n",
        "def download_and_extract():\n",
        "    \"\"\"\n",
        "    Download and extract the STL-10 dataset\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "    dest_directory = DATA_DIR\n",
        "    if not os.path.exists(dest_directory):\n",
        "        os.makedirs(dest_directory)\n",
        "    filename = DATA_URL.split('/')[-1]\n",
        "    filepath = os.path.join(dest_directory, filename)\n",
        "    if not os.path.exists(filepath):\n",
        "        def _progress(count, block_size, total_size):\n",
        "            sys.stdout.write('\\rDownloading %s %.2f%%' % (filename,\n",
        "                float(count * block_size) / float(total_size) * 100.0))\n",
        "            sys.stdout.flush()\n",
        "        filepath, _ = urllib.urlretrieve(DATA_URL, filepath, reporthook=_progress)\n",
        "        print('Downloaded', filename)\n",
        "        tarfile.open(filepath, 'r:gz').extractall(dest_directory)\n",
        "\n",
        "def save_images(images, labels):\n",
        "    print(\"Saving images to disk\")\n",
        "    i = 0\n",
        "    for image in images:\n",
        "        label = labels[i]\n",
        "        directory = './imgtest/' + str(label) + '/'\n",
        "        try:\n",
        "            os.makedirs(directory, exist_ok=True)\n",
        "        except OSError as exc:\n",
        "            if exc.errno == errno.EEXIST:\n",
        "                pass\n",
        "        filename = directory + str(i)\n",
        "        print(filename)\n",
        "        save_image(image, filename)\n",
        "        i = i+1\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # download data if needed\n",
        "    download_and_extract()\n",
        "\n",
        "    # test to check if the image is read correctly\n",
        "    with open(DATA_PATH) as f:\n",
        "        image = read_single_image(f)\n",
        "        plot_image(image)\n",
        "\n",
        "    # test to check if the whole dataset is read correctly\n",
        "    images = read_all_images(DATA_PATH)\n",
        "    print(images.shape)\n",
        "\n",
        "    labels = read_labels(LABEL_PATH)\n",
        "    print(labels.shape)\n",
        "\n",
        "    # save images to disk\n",
        "    save_images(images, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0KbYinbB0ps"
      },
      "outputs": [],
      "source": [
        "#load unlabled data\n",
        "from __future__ import print_function\n",
        "\n",
        "import sys\n",
        "import os, sys, tarfile, errno\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "if sys.version_info >= (3, 0, 0):\n",
        "    import urllib.request as urllib # ugly but works\n",
        "else:\n",
        "    import urllib\n",
        "\n",
        "try:\n",
        "    from imageio import imsave\n",
        "except:\n",
        "    from scipy.misc import imsave\n",
        "\n",
        "print(sys.version_info)\n",
        "\n",
        "# image shape\n",
        "HEIGHT = 96\n",
        "WIDTH = 96\n",
        "DEPTH = 3\n",
        "\n",
        "# size of a single image in bytes\n",
        "SIZE = HEIGHT * WIDTH * DEPTH\n",
        "\n",
        "# path to the directory with the data\n",
        "DATA_DIR = './data'\n",
        "\n",
        "# url of the binary data\n",
        "DATA_URL = 'http://ai.stanford.edu/~acoates/stl10/stl10_binary.tar.gz'\n",
        "\n",
        "# path to the binary train file with image data\n",
        "DATA_PATH = './data/stl10_binary/unlabeled_X.bin'\n",
        "\n",
        "# path to the binary train file with labels\n",
        "#LABEL_PATH = './data/stl10_binary/train_y.bin'\n",
        "\n",
        "def read_labels(path_to_labels):\n",
        "    \"\"\"\n",
        "    :param path_to_labels: path to the binary file containing labels from the STL-10 dataset\n",
        "    :return: an array containing the labels\n",
        "    \"\"\"\n",
        "    with open(path_to_labels, 'rb') as f:\n",
        "        labels = np.fromfile(f, dtype=np.uint8)\n",
        "        return labels\n",
        "\n",
        "\n",
        "def read_all_images(path_to_data):\n",
        "    \"\"\"\n",
        "    :param path_to_data: the file containing the binary images from the STL-10 dataset\n",
        "    :return: an array containing all the images\n",
        "    \"\"\"\n",
        "\n",
        "    with open(path_to_data, 'rb') as f:\n",
        "        # read whole file in uint8 chunks\n",
        "        everything = np.fromfile(f, dtype=np.uint8)\n",
        "\n",
        "        # We force the data into 3x96x96 chunks, since the\n",
        "        # images are stored in \"column-major order\", meaning\n",
        "        # that \"the first 96*96 values are the red channel,\n",
        "        # the next 96*96 are green, and the last are blue.\"\n",
        "        # The -1 is since the size of the pictures depends\n",
        "        # on the input file, and this way numpy determines\n",
        "        # the size on its own.\n",
        "\n",
        "        images = np.reshape(everything, (-1, 3, 96, 96))\n",
        "\n",
        "        # Now transpose the images into a standard image format\n",
        "        # readable by, for example, matplotlib.imshow\n",
        "        # You might want to comment this line or reverse the shuffle\n",
        "        # if you will use a learning algorithm like CNN, since they like\n",
        "        # their channels separated.\n",
        "        images = np.transpose(images, (0, 3, 2, 1))\n",
        "        return images\n",
        "\n",
        "\n",
        "def read_single_image(image_file):\n",
        "    \"\"\"\n",
        "    CAREFUL! - this method uses a file as input instead of the path - so the\n",
        "    position of the reader will be remembered outside of context of this method.\n",
        "    :param image_file: the open file containing the images\n",
        "    :return: a single image\n",
        "    \"\"\"\n",
        "    # read a single image, count determines the number of uint8's to read\n",
        "    image = np.fromfile(image_file, dtype=np.uint8, count=SIZE)\n",
        "    # force into image matrix\n",
        "    image = np.reshape(image, (3, 96, 96))\n",
        "    # transpose to standard format\n",
        "    # You might want to comment this line or reverse the shuffle\n",
        "    # if you will use a learning algorithm like CNN, since they like\n",
        "    # their channels separated.\n",
        "    image = np.transpose(image, (2, 1, 0))\n",
        "    return image\n",
        "\n",
        "\n",
        "def plot_image(image):\n",
        "    \"\"\"\n",
        "    :param image: the image to be plotted in a 3-D matrix format\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "    plt.imshow(image)\n",
        "    plt.show()\n",
        "\n",
        "def save_image(image, name):\n",
        "    imsave(\"%s.png\" % name, image, format=\"png\")\n",
        "\n",
        "def download_and_extract():\n",
        "    \"\"\"\n",
        "    Download and extract the STL-10 dataset\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "    dest_directory = DATA_DIR\n",
        "    if not os.path.exists(dest_directory):\n",
        "        os.makedirs(dest_directory)\n",
        "    filename = DATA_URL.split('/')[-1]\n",
        "    filepath = os.path.join(dest_directory, filename)\n",
        "    if not os.path.exists(filepath):\n",
        "        def _progress(count, block_size, total_size):\n",
        "            sys.stdout.write('\\rDownloading %s %.2f%%' % (filename,\n",
        "                float(count * block_size) / float(total_size) * 100.0))\n",
        "            sys.stdout.flush()\n",
        "        filepath, _ = urllib.urlretrieve(DATA_URL, filepath, reporthook=_progress)\n",
        "        print('Downloaded', filename)\n",
        "        tarfile.open(filepath, 'r:gz').extractall(dest_directory)\n",
        "\n",
        "def save_images(images, labels):\n",
        "    print(\"Saving images to disk\")\n",
        "    i = 0\n",
        "    for image in images:\n",
        "        label = 1\n",
        "        directory = './imgunlable/' + str(label) + '/'\n",
        "        try:\n",
        "            os.makedirs(directory, exist_ok=True)\n",
        "        except OSError as exc:\n",
        "            if exc.errno == errno.EEXIST:\n",
        "                pass\n",
        "        filename = directory + str(i)\n",
        "        print(filename)\n",
        "        save_image(image, filename)\n",
        "        i = i+1\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # download data if needed\n",
        "    download_and_extract()\n",
        "\n",
        "    # test to check if the image is read correctly\n",
        "    with open(DATA_PATH) as f:\n",
        "        image = read_single_image(f)\n",
        "        plot_image(image)\n",
        "\n",
        "    # test to check if the whole dataset is read correctly\n",
        "    images = read_all_images(DATA_PATH)\n",
        "    print(images.shape)\n",
        "\n",
        "    labels = read_labels(LABEL_PATH)\n",
        "    print(labels.shape)\n",
        "\n",
        "    # save images to disk\n",
        "    save_images(images, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkp17Owu-jKZ",
        "outputId": "ccad0845-e80c-4319-c3fc-f77740e44495"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/101.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/101.7 kB\u001b[0m \u001b[31m685.7 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m71.7/101.7 kB\u001b[0m \u001b[31m986.0 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (23.2)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.6.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install  tensorboardX"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python \"individualbadstl96-res.py\"  --dataset stl10  --num_labeled 500 --num_valid_samples 0 --root_dir experiments/ --data_dir data/stl10/ --batch_size 100  --arch res --dropout 0.0 --mixup_consistency 100.0 --pseudo_label mean_teacher  --consistency_rampup_starts 0 --consistency_rampup_ends 100 --epochs 400  --lr_rampdown_epochs 450 --print_freq 200 --momentum 0.9 --lr 0.1 --ema_decay 0.999  --mixup_sup_alpha 1.0 --mixup_usup_alpha 1.0"
      ],
      "metadata": {
        "id": "7U4scxJZb4VJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_w-uFk3-bIx"
      },
      "outputs": [],
      "source": [
        "!python \"individualbadstl96-transformer.py\"  --dataset stl10  --num_labeled 500 --num_valid_samples 0 --root_dir experiments/ --data_dir data/stl10/ --batch_size 8  --arch res --dropout 0.0 --mixup_consistency 100.0 --pseudo_label mean_teacher  --consistency_rampup_starts 0 --consistency_rampup_ends 100 --epochs 400  --lr_rampdown_epochs 450 --print_freq 200 --momentum 0.9 --lr 0.1 --ema_decay 0.999  --mixup_sup_alpha 1.0 --mixup_usup_alpha 1.0"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
